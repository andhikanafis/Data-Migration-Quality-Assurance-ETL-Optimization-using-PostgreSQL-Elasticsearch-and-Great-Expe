
# Employee Attrition Data Analysis: Automated ETL from PostgreSQL to Elasticsearch Using Airflow & Great Expectations

## Problem Statement
This project aims to streamline and enhance the ETL processes involved in migrating data from a PostgreSQL database to Elasticsearch. While automation is a core objective, ensuring data quality, consistency, and reliability during these operations is equally crucial. Leveraging the capabilities of "Great Expectations," this project places a significant emphasis on validating data at each step, ensuring that the migrated data meets the defined quality standards. The dataset used in this initiative provides insights into factors influencing employee attrition rates in companies, making the need for precise and trustworthy data even more imperative.

## Objective
The main objectives are:
- Streamline the ETL process by automating data transformations and migrations between PostgreSQL and Elasticsearch.
- Ensure data quality and validation using Great Expectations.
- Provide insights into employee behavior and factors influencing attrition.

## Tools/Methods Used
- **PostgreSQL**: Used as the primary database source.
- **Elasticsearch**: Target system for data population.
- **Airflow**: Orchestrating and automating the ETL processes.
- **Great Expectations**: Conducting data validation and quality checks in the Jupyter notebook.

## How to Use
1. Ensure you have the required libraries and systems set up, including PostgreSQL, Elasticsearch, and Airflow.
2. Clone the repository containing the provided scripts and notebook.
3. Update the connection strings and configurations in the scripts to match your server details.
4. Execute the scripts to perform the ETL operations.
5. Open the Jupyter Notebook to perform data validation and quality checks using Great Expectations.

---

For any queries or feedback, please contact the author [Andhika Abdurachim Nafis](https://github.com/andhikanafis).
